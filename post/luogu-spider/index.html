<!DOCTYPE html><html lang="cn"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta content="IE=edge" http-equiv="X-UA-Compatible"><title>洛谷爬虫 - 宝硕博客</title><link rel="icon" href="https://cdn.jsdelivr.net/npm/bsi@0.0.2/favicon/16x16.png"><link rel="preconnect" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="preconnect" href="https://i.loli.net"><link rel="preconnect" href="https://vip1.loli.net"><link rel="preconnect" href="https://vip2.loli.net"><link rel="preconnect" href="https://vip1.loli.io"><link rel="preconnect" href="https://vip2.loli.io"><link rel="preload" href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,400;0,700;1,400;1,700&family=Roboto+Mono:ital,wght@0,400;0,700;1,400;1,700&display=swap" as="style" onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,400;0,700;1,400;1,700&family=Roboto+Mono:ital,wght@0,400;0,700;1,400;1,700&display=swap"></noscript><link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" as="style" onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"></noscript><link rel="alternate" href="/rss.xml" title="宝硕博客" type="application/rss+xml"><link rel="alternate" href="/atom.xml" title="宝硕博客" type="application/atom+xml"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bsm@0.2.4/dist/css/main.css"><script>window.ga_tid="UA-163290903-2",window.ga_api="https://api.baoshuo.ren/cfga/jquery.js"</script><script async src="https://cdn.jsdelivr.net/npm/cfga@1.0.3/cfga.min.js"></script><meta name="color-scheme" content="light dark"><script src="https://cdn.jsdelivr.net/npm/bsm@0.2.4/dist/js/darkmode.js"></script><meta name="description" content="截至目前，洛谷已经有了近两万道题目和四十余万名用户。本代码爬取了一些样本，以供后续（可能）的数据分析。"><meta property="og:type" content="article"><meta property="og:title" content="洛谷爬虫 - 宝硕博客"><meta property="og:url" content="https://blog.baoshuo.ren/post/luogu-spider/"><meta property="og:site_name" content="宝硕博客"><meta property="og:description" content="截至目前，洛谷已经有了近两万道题目和四十余万名用户。本代码爬取了一些样本，以供后续（可能）的数据分析。"><meta property="og:locale"><meta property="og:image" content="https://cdn.jsdelivr.net/npm/bsi@0.0.2/favicon/144x144.png"><meta property="article:published_time" content="2020-11-26T06:55:02.000Z"><meta property="article:modified_time" content="2021-03-20T16:28:24.856Z"><meta property="article:author" content="宝硕"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://cdn.jsdelivr.net/npm/bsi@0.0.2/favicon/144x144.png"><meta name="twitter:creator" content="@renbaoshuo"><meta name="twitter:site" content="renbaoshuo"><script>// Check that service workers are supported
    if ('serviceWorker' in navigator) {
        // Use the window load event to keep the page load performant
        window.addEventListener('load', () => {
            navigator.serviceWorker.register('/sw.js');
        });
    }</script><meta name="generator" content="Hexo 5.3.0"></head><body><div class="container"><main><a class="skip-link" href="#main">Skip to main</a><header class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img class="user-avatar" src="https://cdn.jsdelivr.net/npm/bsi@0.0.2/favicon/64x64.png" alt="Avatar"><div class="site-name">宝硕博客</div></a><button aria-label="Navbar Toggler" class="navbar-toggler" type="button" id="changeNavbar"><i class="content-first" style="font-size:18px"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" height="18px" fill="currentColor"><path d="M16 132h416c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163 0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"/></svg></i></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><div class="navbar-nav"><div class="nav-item"><a href="/" class="menu gt-a-link">首页</a></div><div class="nav-item"><a href="/archives/" class="menu gt-a-link">归档</a></div><div class="nav-item"><a href="/categories/" class="menu gt-a-link">分类</a></div><div class="nav-item"><a href="/tags/" class="menu gt-a-link">标签</a></div><div class="nav-item"><a href="/friends/" class="menu gt-a-link">友链</a></div><div class="nav-item"><a href="/about/" class="menu gt-a-link">关于</a></div><div class="nav-item" style="padding:1.0625rem 1.25rem .6875rem 1.25rem"><a href="/search/" class="menu"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" height="16" width="16"><path fill="currentColor" d="M508.5 468.9L387.1 347.5c-2.3-2.3-5.3-3.5-8.5-3.5h-13.2c31.5-36.5 50.6-84 50.6-136C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c52 0 99.5-19.1 136-50.6v13.2c0 3.2 1.3 6.2 3.5 8.5l121.4 121.4c4.7 4.7 12.3 4.7 17 0l22.6-22.6c4.7-4.7 4.7-12.3 0-17zM208 368c-88.4 0-160-71.6-160-160S119.6 48 208 48s160 71.6 160 160-71.6 160-160 160z"/></svg></a></div><div class="nav-item" style="padding:1.0625rem 1.25rem .6875rem 1.25rem"><a href="javascript:applyCustomDarkModeSettings(toggleCustomDarkMode());" class="menu"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" height="16" width="16"><path fill="currentColor" d="M256 56c110.549 0 200 89.468 200 200 0 110.549-89.468 200-200 200-110.549 0-200-89.468-200-200 0-110.549 89.468-200 200-200m0-48C119.033 8 8 119.033 8 256s111.033 248 248 248 248-111.033 248-248S392.967 8 256 8zm0 96c-83.947 0-152 68.053-152 152s68.053 152 152 152V104z"/></svg></a></div></div></div></header><script src="https://cdn.jsdelivr.net/npm/bsm@0.2.4/dist/js/main.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bsm@0.2.4/dist/css/post.css"><div class="post-container" id="post-container"><h1 class="post-title" id="post-title">洛谷爬虫</h1><div class="post-info" id="post-info"><a href="/categories/%E6%8A%80%E6%9C%AF/" class="category">技术</a> · <time class="time" id="post-time">2020-11-26</time> ·</div><hr><div class="content" id="post-content"><p>截至目前，洛谷已经有了近两万道题目和四十余万名用户。本代码爬取了一些样本，以供后续（可能）的数据分析。</p><a id="more"></a><p>本次爬取遵守洛谷的 <code>robots.txt</code> 中的要求，不爬取提交记录页面。为了避免影响洛谷的正常运行，脚本只采用单线程进行爬取。</p><pre><code class="highlight groovy">User-<span class="attr">Agent:</span> *
<span class="attr">Disallow:</span> /record
<span class="attr">Disallow:</span> /recordnew</code></pre><h2 id="爬取题目信息"><a class="anchor" href="#爬取题目信息"></a>爬取题目信息</h2><h3 id="题目数据获取"><a class="anchor" href="#题目数据获取"></a>题目数据获取</h3><p>先使用 <code>curl</code> 获取洛谷的题目页面：</p><p><img src="https://vip1.loli.io/2020/11/26/JageUdcpXTthIjM.png" alt="" loading="lazy"></p><p>可以看出我们需要的数据都在传入给 <code>decodeURIComponent()</code> 函数的字符串中，正则匹配取出即可。</p><p>下面是代码实现：</p><pre><code class="highlight python"><span class="comment">#!/usr/bin/python3</span>
<span class="comment"># coding: utf-8</span>

<span class="keyword">import</span> requests
<span class="keyword">import</span> re
<span class="keyword">import</span> json
<span class="keyword">from</span> urllib.parse <span class="keyword">import</span> unquote

<span class="comment"># 设置请求头</span>
headers = &#123;
    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36 Spider/0.1&quot;</span>
&#125;

<span class="function"><span class="keyword">def</span> <span class="title">getProblemJSON</span>(<span class="params">pid</span>):</span>
    <span class="keyword">return</span> json.loads(unquote(<span class="built_in">str</span>(re.findall(<span class="string">r&#x27;decodeURIComponent\(&quot;(.*)&quot;\)&#x27;</span>, requests.get(url=<span class="string">&quot;https://www.luogu.com.cn/problem/P1000&quot;</span>, headers=headers).text)[<span class="number">0</span>])))

data = getProblemJSON(<span class="string">&quot;P1000&quot;</span>)
print(json.dumps(data[<span class="string">&#x27;currentData&#x27;</span>], sort_keys=<span class="literal">True</span>, indent=<span class="number">4</span>))</code></pre><div class="scode warn"><p class="scode-title">Update at 2021/02/05</p><p>添加参数 <code>_contentOnly=1</code> 可以直接获取JSON格式的信息，无需再正则匹配。</p><pre><code class="highlight diff"><span class="comment">--- a/tools/spider.py</span>
<span class="comment">+++ b/tools/spider.py</span>
<span class="meta">@@ -19,8 +19,7 @@</span>
 def getProblem(pid):
<span class="deletion">-    url = f&quot;https://www.luogu.com.cn/problem/&#123;pid&#125;&quot;</span>
<span class="deletion">-    redata = re.findall(r&#x27;decodeURIComponent\(&quot;(.*)&quot;\)&#x27;,</span>
<span class="deletion">-                        requests.get(url, headers=headers).text)</span>
<span class="addition">+    url = f&quot;https://www.luogu.com.cn/problem/&#123;pid&#125;?_contentOnly=1&quot;</span>
<span class="addition">+    redata = requests.get(url, headers=headers).text</span>
     if len(redata) == 0:
         return &#123; &quot;code&quot;: 403 &#125;
     else:
<span class="deletion">-        return json.loads(unquote(redata[0]))</span>
<span class="addition">+        return json.loads(redata)</span></code></pre></div><h3 id="处理题目数据"><a class="anchor" href="#处理题目数据"></a>处理题目数据</h3><p>这里只留下 <code>currentData.problem</code> 字段里面的内容即可。</p><pre><code class="highlight python"><span class="comment">#!/usr/bin/python3</span>
<span class="comment"># coding: utf-8</span>

<span class="keyword">import</span> requests
<span class="keyword">import</span> re
<span class="keyword">import</span> json
<span class="keyword">from</span> urllib.parse <span class="keyword">import</span> unquote

f = <span class="built_in">open</span>(<span class="string">&#x27;problems.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)
res = []

headers = &#123;
    <span class="string">&quot;user-agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4331.0 Safari/537.36 spider/0.1&quot;</span>,
&#125;


<span class="function"><span class="keyword">def</span> <span class="title">getProblem</span>(<span class="params">pid</span>):</span>
    <span class="keyword">return</span> json.loads(requests.get(<span class="string">f&quot;https://www.luogu.com.cn/problem/<span class="subst">&#123;pid&#125;</span>?_contentOnly=1&quot;</span>, headers=headers).text)[<span class="string">&#x27;currentData&#x27;</span>]


<span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>, <span class="number">1010</span>):
    tmpdict = &#123;&#125;
    tmpdict[<span class="string">&quot;pid&quot;</span>] = <span class="string">f&quot;P<span class="subst">&#123;i&#125;</span>&quot;</span>
    tmpdict[<span class="string">&quot;data&quot;</span>] = getProblem(<span class="string">f&quot;P<span class="subst">&#123;i&#125;</span>&quot;</span>)[<span class="string">&quot;problem&quot;</span>]
    res.append(tmpdict)

<span class="comment"># print(res)</span>
f.write(json.dumps(res, indent=<span class="number">4</span>).replace(<span class="string">&quot;\\t&quot;</span>, <span class="string">&quot;    &quot;</span>))</code></pre><h3 id="最终代码"><a class="anchor" href="#最终代码"></a>最终代码</h3><pre><code class="highlight python"><span class="comment">#!/usr/bin/python3</span>
<span class="comment"># coding: utf-8</span>

<span class="keyword">import</span> requests
<span class="keyword">import</span> json
<span class="keyword">import</span> time
<span class="keyword">import</span> pymongo

dbclient = pymongo.MongoClient(<span class="string">&quot;mongodb://127.0.0.1:27017/&quot;</span>)
luogudb = dbclient[<span class="string">&quot;luogu&quot;</span>]
dbcol = luogudb[<span class="string">&quot;problem&quot;</span>]

headers = &#123;
    <span class="string">&quot;user-agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4331.0 Safari/537.36 spider/0.1&quot;</span>,
&#125;


<span class="function"><span class="keyword">def</span> <span class="title">getProblem</span>(<span class="params">pid</span>):</span>
    url = <span class="string">f&quot;https://www.luogu.com.cn/problem/<span class="subst">&#123;pid&#125;</span>?_contentOnly=1&quot;</span>
    redata = requests.get(url, headers=headers).text
    <span class="keyword">return</span> json.loads(redata)

<span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>, <span class="number">7103</span>):
    pid = <span class="string">f&quot;P<span class="subst">&#123;i&#125;</span>&quot;</span>
    <span class="keyword">if</span> <span class="built_in">list</span>(dbcol.find(&#123;<span class="string">&#x27;pid&#x27;</span>: pid&#125;)) == []:
        tmpdict = &#123;&#125;
        tmpdict[<span class="string">&quot;pid&quot;</span>] = pid
        tmpdata = getProblem(pid)
        <span class="keyword">if</span> tmpdata[<span class="string">&quot;code&quot;</span>] == <span class="number">200</span>:
            tmpdict[<span class="string">&quot;data&quot;</span>] = getProblem(pid)[<span class="string">&quot;currentData&quot;</span>][<span class="string">&quot;problem&quot;</span>]
            dbcol.insert_one(tmpdict)
            print(<span class="string">f&quot;Successfully get problem <span class="subst">&#123;pid&#125;</span>.&quot;</span>)
            time.sleep(<span class="number">1</span>)
        <span class="keyword">else</span>:
            print(<span class="string">f&quot;Fail to get problem <span class="subst">&#123;pid&#125;</span>.&quot;</span>)
    <span class="keyword">else</span>:
        print(<span class="string">f&quot;Problem <span class="subst">&#123;pid&#125;</span> is already exists.&quot;</span>)</code></pre><p>有关于数据库读写的部分请参考下文的 <a href="#%E6%95%B0%E6%8D%AE%E5%BA%93">数据库</a> 部分。</p><h2 id="爬取用户信息"><a class="anchor" href="#爬取用户信息"></a>爬取用户信息</h2><p>结构与题目爬虫类似，故不再作代码说明。</p><pre><code class="highlight python"><span class="keyword">import</span> json
<span class="keyword">import</span> time
<span class="keyword">import</span> pymongo
<span class="keyword">import</span> requests

dbclient = pymongo.MongoClient(<span class="string">&quot;mongodb://127.0.0.1:27017/&quot;</span>)
luogudb = dbclient[<span class="string">&quot;luogu&quot;</span>]
dbcol = luogudb[<span class="string">&quot;user&quot;</span>]

headers = &#123; <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4331.0 Safari/537.36&quot;</span>, &#125;

<span class="function"><span class="keyword">def</span> <span class="title">getUser</span>(<span class="params">uid</span>):</span>
    url = <span class="string">f&quot;https://www.luogu.com.cn/user/<span class="subst">&#123;uid&#125;</span>?_contentOnly=1&quot;</span>
    redata = requests.get(url, headers=headers).text
    <span class="keyword">return</span> json.loads(redata)

<span class="keyword">for</span> uid <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">2</span>):
    <span class="keyword">if</span> <span class="built_in">list</span>(dbcol.find(&#123;<span class="string">&#x27;uid&#x27;</span>: uid&#125;)) == []:
        tmpdict = &#123;&#125;
        tmpdict[<span class="string">&quot;_id&quot;</span>] = uid
        tmpdict[<span class="string">&quot;uid&quot;</span>] = uid
        tmpdata = getUser(uid)
        <span class="keyword">if</span> tmpdata[<span class="string">&quot;code&quot;</span>] == <span class="number">200</span>:
            tmpdict[<span class="string">&quot;data&quot;</span>] = tmpdata[<span class="string">&quot;currentData&quot;</span>][<span class="string">&quot;user&quot;</span>]
            dbcol.insert_one(tmpdict)
            print(<span class="string">f&quot;Successfully get user <span class="subst">&#123;uid&#125;</span>.&quot;</span>)
            time.sleep(<span class="number">0.5</span>)
        <span class="keyword">else</span>:
            print(<span class="string">f&quot;Fail to get user <span class="subst">&#123;uid&#125;</span>.&quot;</span>)
            time.sleep(<span class="number">0.5</span>)
    <span class="keyword">else</span>:
        print(<span class="string">f&quot;User <span class="subst">&#123;uid&#125;</span> is already exists.&quot;</span>)</code></pre><h2 id="数据库"><a class="anchor" href="#数据库"></a>数据库</h2><h3 id="搭建数据库"><a class="anchor" href="#搭建数据库"></a>搭建数据库</h3><p>搭建 MongoDB 数据库只需要在 docker 里面跑一个容器，非常简便。</p><pre><code class="highlight bash">docker run -v /root/data/mongo:/data/db -itd --name mongo -p 27017:27017 mongo</code></pre><h3 id="连接数据库"><a class="anchor" href="#连接数据库"></a>连接数据库</h3><pre><code class="highlight python">client = pymongo.MongoClient(<span class="string">&quot;mongodb://127.0.0.1:27017/&quot;</span>)
luogudb = dbclient[<span class="string">&quot;luogu&quot;</span>]
col = luogudb[<span class="string">&quot;problem&quot;</span>]</code></pre><h3 id="存储数据"><a class="anchor" href="#存储数据"></a>存储数据</h3><pre><code class="highlight python"><span class="keyword">if</span> <span class="built_in">list</span>(col.find(&#123;<span class="string">&#x27;pid&#x27;</span> : pid&#125;)) == []:
    col.insert_one(data)
    print(<span class="string">&quot;Success.&quot;</span>)
<span class="keyword">else</span>:
    print(<span class="string">&quot;Already exists.&quot;</span>)</code></pre><h3 id="读取数据"><a class="anchor" href="#读取数据"></a>读取数据</h3><pre><code class="highlight python">print(<span class="built_in">list</span>(col.find()))</code></pre><h2 id="web-管理数据库"><a class="anchor" href="#web-管理数据库"></a>web 管理数据库</h2><p>再跑一个 <code>mongo-express</code> 就行了。</p><pre><code class="highlight bash">docker run -d --name mongo-express -e ME_CONFIG_MONGODB_SERVER=host.docker.internal -p 8081:8081 mongo-express</code></pre><p>访问 <code>ip:8081</code> 就能看到管理界面了。</p><h2 id="导出数据库"><a class="anchor" href="#导出数据库"></a>导出数据库</h2><p>直接运行下方命令导出为 JSON 格式即可。</p><pre><code class="highlight bash">mongoexport -d luogu -c problem -o /data/db/problem.json</code></pre><p>或者点击对应数据库管理界面中的 <code>[JSON]</code> 按钮导出。</p><p><img src="https://vip2.loli.io/2020/11/26/hXtVAynYGcb8B71.png" alt="" loading="lazy"></p><h2 id="成果"><a class="anchor" href="#成果"></a>成果</h2><p>断断续续爬了一个多星期，终于爬完了。</p><p><img src="https://vip1.loli.io/2020/11/26/7muojQZM125gWXL.png" alt="" loading="lazy"></p></div></div><div class="hidden" id="article-expire">本文最后更新于 <span id="article-expire-day">-1</span> 天前，文中所描述的信息可能已发生改变。</div><div class="license" id="post-license"><div class="license-title">洛谷爬虫</div><div class="license-link"><a href="https://blog.baoshuo.ren/post/luogu-spider/">https://blog.baoshuo.ren/post/luogu-spider/</a></div><div class="license-meta"><div class="license-meta-item"><div class="license-meta-title">本文作者</div><div class="license-meta-text">宝硕</div></div><div class="license-meta-item"><div class="license-meta-title">发布于</div><div class="license-meta-text">2020-11-26</div></div><div class="license-meta-item"><div class="license-meta-title">更新于</div><div class="license-meta-text">2021-03-21</div></div><div class="license-meta-item"><div class="license-meta-title">许可协议</div><div class="license-meta-text"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="external nofollow noopener noopenner noreferrer">CC BY-NC-SA 4.0</a></div></div></div></div><div class="afdian" id="afdian"><div class="donation-label">喜欢这篇文章？为什么不考虑打赏一下作者呢？</div><a class="afdian-button button" href="https://afdian.net/@baoshuo" rel="nofollow noopener" target="_blank">爱发电</a></div><div class="pagination-container" id="pagination"><div class="prev-page">上一篇：<a href="/post/download-smms-image/">【随笔】下载自己在 SM.MS 图床上的所有图片</a></div><div class="next-page">下一篇：<a href="/post/change-git-submission-email/">【随笔】批量修改 Git 仓库的提交邮箱</a></div></div><script>let updated = Math.floor((new Date().getTime() - 1616257704856) / 864e5);
        if(updated > 182) {
            document.getElementById("article-expire-day").textContent = updated;
            document.getElementById("article-expire").classList.remove("hidden");
        }</script><div id="disqus_thread"></div><script>var disqus_options={shortname:"baoshuo",api:"https://api.baoshuo.ren/disqus/api/",apikey:"SysuSvnZJi7nYvWwH14fu42b1CowDBsAH3Ol3UIsqdRbEcQwGFpWuUPkcX93ffCJ",identifier:location.pathname,title:"洛谷爬虫",siteName:"宝硕博客",admin:"renbaoshuo"}</script><script src="https://cdn.jsdelivr.net/npm/bsm@0.2.4/dist/js/disqus.lazyload.js"></script><script src="https://cdn.jsdelivr.net/npm/@nishanths/zoom.js@3.1.0/dist/zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/bsm@0.2.4/dist/js/post.js"></script><footer class="footer"><div><a href="/atom.xml" target="_blank">RSS</a> | <a target="_blank" href="https://beian.miit.gov.cn" rel="nofollow noopener">冀ICP备15024669号</a> | <a target="_blank" rel="noopener" href="https://twitter.com/renbaoshuo">Twitter @renbaoshuo</a></div><div>Theme <a target="_blank" rel="noopener" href="https://github.com/renbaoshuo/hexo-theme-pure">Pure</a> by <a rel="noopener" href="https://baoshuo.ren" target="_blank">Baoshuo</a> | Powered by <a href="https://hexo.io" rel="nofollow noopener" target="_blank">Hexo</a></div></footer><script async src="https://cdn.jsdelivr.net/npm/instant.page@5.1.0/instantpage.min.js"></script><div class="fab"><a aria-label="回到顶部" class="fab-btn" href="#" title="回到顶部"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512" height="25" width="25"><path fill="currentColor" d="M168.5 164.2l148 146.8c4.7 4.7 4.7 12.3 0 17l-19.8 19.8c-4.7 4.7-12.3 4.7-17 0L160 229.3 40.3 347.8c-4.7 4.7-12.3 4.7-17 0L3.5 328c-4.7-4.7-4.7-12.3 0-17l148-146.8c4.7-4.7 12.3-4.7 17 0z"/></svg></a></div></main></div></body></html>